# -*- coding: utf-8 -*-
"""Sentimen Analysis Classroom.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cOJ_MrBrlOyG8GTYXcPJCVwLNJlDI9_-

Sentimen Analysis
"""

pip install Sastrawi

#Import required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns
import string
import re
import nltk
nltk.download('punkt')
nltk.download('stopwords')

df =  pd.read_csv('/content/sample_data/hasil_proses_pradataset.tsv',delimiter='\t',names= ['value','komentar'])
df.head()

#import stopword
from nltk.tokenize import sent_tokenize, word_tokenize
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory

def pre_process(text):
    # Case Folding: Lowercase
    # Merubah format teks menjadi format huruf kecil semua (lowercase).
    text = text.lower()

    # Case Folding: Removing Number
    # Menghapus karakter angka.
    text = re.sub(r"\d", "", text)

    # Case Folding: Removing Punctuation
    # Menghapus karakter tanda baca.
    text = text.translate(str.maketrans("","",string.punctuation))

    # Case Folding: Removing Whitespace
    # Menghapus karakter kosong.
    text = text.strip()

    #Separating Sentences with Split () Method
    #Fungsi split() memisahkan string ke dalam list dengan spasi sebagai pemisah jika tidak ditentukan pemisahnya.
    pisah = text.split()

    #Tokenizing: Word Tokenizing Using NLTK Module
    #Menggunakan Library NLTK untuk memisahkan kata dalam sebuah kalimat.
    tokens = nltk.tokenize.word_tokenize(text)

    #Filtering using sastrawi
    factory = StopWordRemoverFactory()
    stopword = factory.create_stop_word_remover()
    text = stopword.remove(text)

    return text

df['komentar'] = df['komentar'].apply(lambda x:pre_process(x))
df.head()

#Vectorization
from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer()
cv.fit(df['komentar'])
X = cv.transform(df['komentar'])

y = df['value']

#Build Classfier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.80)

# Commented out IPython magic to ensure Python compatibility.
#find the best value of C in logistic regression

for c in [0.01, 0.05, 0.25, 0.5, 1]:

  lr = LogisticRegression(C=c)
  lr.fit(X_train, y_train)
  print('Accuracy for C=%s: %s'
#        % (c, accuracy_score(y_test, lr.predict(X_test))))

# Commented out IPython magic to ensure Python compatibility.
#find the best value of C in support vector
for c in [0.01, 0.05, 0.25, 0.5, 1]:

  sv = SVC(C=c)
  sv.fit(X_train, y_train)
  print('Accuracy for C=%s: %s'
#        % (c, accuracy_score(y_test, lr.predict(X_test))))

#Here I choose C=1 to build the final model for Logistic Regression
final_model_lr = LogisticRegression(C=1)
final_model_lr.fit(X, y)
print('Final Model Accuracy: %s' %accuracy_score(y_test, final_model_lr.predict(X_test)))

#Here I choose C=1 to build the final model for support vector
final_model_sv = SVC(C=1)
final_model_sv.fit(X, y)
print('Final Model Accuracy: %s' %accuracy_score(y_test, final_model_sv.predict(X_test)))